{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log, e\n",
    "pd.util.testing.N = 100\n",
    "pd.util.testing.K = 50"
   ]
  },
  {
   "source": [
    "# Generate Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.util.testing.makeMixedDataFrame()\n",
    "df = df.merge(df, left_index=True, right_index=True)\n",
    "df = dd.from_pandas(df, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels, base=None):\n",
    "  \"\"\" Computes entropy of label distribution. \n",
    "  \n",
    "  References:\n",
    "    [1] https://stackoverflow.com/questions/15450192/fastest-way-to-compute-entropy-in-python\n",
    "  \"\"\"\n",
    "\n",
    "  n_labels = len(labels)\n",
    "\n",
    "  if n_labels <= 1:\n",
    "    return 0\n",
    "\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / n_labels\n",
    "  n_classes = np.count_nonzero(probs)\n",
    "\n",
    "  if n_classes <= 1:\n",
    "    return 0\n",
    "\n",
    "  ent = 0.\n",
    "\n",
    "  # Compute entropy\n",
    "  base = e if base is None else base\n",
    "  for i in probs:\n",
    "    ent -= i * log(i, base)\n",
    "\n",
    "  return ent"
   ]
  },
  {
   "source": [
    "# Filter Nulls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nulls(data: dask.dataframe, nulls_threshold: float):\n",
    "\n",
    "    summary_df = data.isnull().sum().compute()\n",
    "    summary_df = summary_df.to_frame(name=\"nulls_count\")\n",
    "    summary_df[\"nulls_proportions\"] = summary_df[\"nulls_count\"] / data.shape[0].compute()\n",
    "    summary_df.sort_values(by=\"nulls_count\", ascending=False, inplace=True)\n",
    "\n",
    "    mask_nulls = summary_df[\"nulls_proportions\"] > nulls_threshold\n",
    "    summary_df.loc[mask_nulls, \"filtered_nulls\"]  = 1\n",
    "    summary_df.loc[~mask_nulls, \"filtered_nulls\"]  = 0\n",
    "    \n",
    "    removed_cols = list(summary_df[mask_nulls].index.values)\n",
    "\n",
    "    return data.drop(labels=removed_cols, axis=1), summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, summary = filter_nulls(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nulls_count  nulls_proportions  filtered_nulls\n",
       "A_x            0                0.0             0.0\n",
       "B_x            0                0.0             0.0\n",
       "C_x            0                0.0             0.0\n",
       "D_x            0                0.0             0.0\n",
       "A_y            0                0.0             0.0\n",
       "B_y            0                0.0             0.0\n",
       "C_y            0                0.0             0.0\n",
       "D_y            0                0.0             0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nulls_count</th>\n      <th>nulls_proportions</th>\n      <th>filtered_nulls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>B_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>C_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>D_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>A_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>B_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>C_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>D_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "source": [
    "# Numerical Variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_numerical_variance(data: dask.dataframe, variance_thresholds: list=[0, np.inf], inclusive: bool=False):\n",
    "\n",
    "    summary_df = data.select_dtypes(include=[np.number]).describe().compute()\n",
    "    summary_df = summary_df.T.reset_index()\n",
    "    summary_df.rename(columns={\"index\": \"column_name\"}, inplace=True)\n",
    "    summary_df.sort_values(by=\"column_name\", inplace=True)\n",
    "\n",
    "    thresholds = [float(value) for value in variance_thresholds]\n",
    "    mask_variance = summary_df[\"std\"].between(min(thresholds), max(thresholds), inclusive=inclusive)\n",
    "\n",
    "    removed_cols = list(summary_df.loc[~mask_variance, \"column_name\"].values)\n",
    "    mask_removed = summary_df[\"column_name\"].isin(removed_cols)\n",
    "    \n",
    "    summary_df.loc[mask_removed, \"filtered_variance\"]  = 1\n",
    "    summary_df.loc[~mask_removed, \"filtered_variance\"]  = 0\n",
    "    \n",
    "    return data.drop(labels=removed_cols, axis=1), summary_df.set_index(\"column_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, num_summary = filter_numerical_variance(df, [0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             count  mean       std  min  25%  50%  75%  max  \\\n",
       "column_name                                                   \n",
       "A_x            5.0   2.0  1.581139  0.0  1.0  2.0  3.0  4.0   \n",
       "A_y            5.0   2.0  1.581139  0.0  1.0  2.0  3.0  4.0   \n",
       "B_x            5.0   0.4  0.547723  0.0  0.0  0.0  1.0  1.0   \n",
       "B_y            5.0   0.4  0.547723  0.0  0.0  0.0  1.0  1.0   \n",
       "\n",
       "             Removed due to Variance  \n",
       "column_name                           \n",
       "A_x                              0.0  \n",
       "A_y                              0.0  \n",
       "B_x                              0.0  \n",
       "B_y                              0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>Removed due to Variance</th>\n    </tr>\n    <tr>\n      <th>column_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A_x</th>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.581139</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>A_y</th>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.581139</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>B_x</th>\n      <td>5.0</td>\n      <td>0.4</td>\n      <td>0.547723</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>B_y</th>\n      <td>5.0</td>\n      <td>0.4</td>\n      <td>0.547723</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "num_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.merge(num_summary, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "source": [
    "# Categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_categorical_variance(data: dask.dataframe, entropy_thresholds: list=[0, np.inf], inclusive: bool=False):\n",
    "\n",
    "    summary_df = data.select_dtypes(exclude=[np.number], include=[\"object\"]).describe().compute()\n",
    "    summary_df = summary_df.T\n",
    "\n",
    "    entropies = data.select_dtypes(exclude=[np.number], include=[\"object\"]).compute().apply(entropy, axis=0)\n",
    "    entropies = entropies.to_frame(name=\"entropy\")\n",
    "\n",
    "    summary_df = summary_df.merge(entropies, left_index=True, right_index=True)\n",
    "\n",
    "    summary_df.reset_index(inplace=True)\n",
    "    summary_df.rename(columns={\"index\": \"column_name\"}, inplace=True)\n",
    "    summary_df.sort_values(by=\"column_name\", inplace=True)\n",
    "\n",
    "    thresholds = [float(value) for value in entropy_thresholds]\n",
    "    mask_entropy = summary_df[\"entropy\"].between(min(thresholds), max(thresholds), inclusive=inclusive)\n",
    "    removed_cols = list(summary_df.loc[~mask_entropy, \"column_name\"].values)\n",
    "    mask_removed = summary_df[\"column_name\"].isin(removed_cols)\n",
    "    summary_df.loc[mask_removed, \"Removed\"]  = 1\n",
    "    summary_df.loc[~mask_removed, \"Removed\"]  = 0\n",
    "    \n",
    "    return data.drop(labels=removed_cols, axis=1), summary_df.set_index(\"column_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, summary_cat = filter_categorical_variance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Nulls Count  Nulls Proportions  Removed due to Nulls  count_x  mean  \\\n",
       "A_x            0                0.0                   0.0      5.0   2.0   \n",
       "B_x            0                0.0                   0.0      5.0   0.4   \n",
       "C_x            0                0.0                   0.0      NaN   NaN   \n",
       "D_x            0                0.0                   0.0      NaN   NaN   \n",
       "A_y            0                0.0                   0.0      5.0   2.0   \n",
       "B_y            0                0.0                   0.0      5.0   0.4   \n",
       "C_y            0                0.0                   0.0      NaN   NaN   \n",
       "D_y            0                0.0                   0.0      NaN   NaN   \n",
       "\n",
       "          std  min  25%  50%  75%  max  Removed due to Variance unique  \\\n",
       "A_x  1.581139  0.0  1.0  2.0  3.0  4.0                      0.0    NaN   \n",
       "B_x  0.547723  0.0  0.0  0.0  1.0  1.0                      0.0    NaN   \n",
       "C_x       NaN  NaN  NaN  NaN  NaN  NaN                      NaN      5   \n",
       "D_x       NaN  NaN  NaN  NaN  NaN  NaN                      NaN    NaN   \n",
       "A_y  1.581139  0.0  1.0  2.0  3.0  4.0                      0.0    NaN   \n",
       "B_y  0.547723  0.0  0.0  0.0  1.0  1.0                      0.0    NaN   \n",
       "C_y       NaN  NaN  NaN  NaN  NaN  NaN                      NaN      5   \n",
       "D_y       NaN  NaN  NaN  NaN  NaN  NaN                      NaN    NaN   \n",
       "\n",
       "    count_y   top freq   entropy  Removed  \n",
       "A_x     NaN   NaN  NaN       NaN      NaN  \n",
       "B_x     NaN   NaN  NaN       NaN      NaN  \n",
       "C_x       5  foo5    1  1.609438      0.0  \n",
       "D_x     NaN   NaN  NaN       NaN      NaN  \n",
       "A_y     NaN   NaN  NaN       NaN      NaN  \n",
       "B_y     NaN   NaN  NaN       NaN      NaN  \n",
       "C_y       5  foo5    1  1.609438      0.0  \n",
       "D_y     NaN   NaN  NaN       NaN      NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Nulls Count</th>\n      <th>Nulls Proportions</th>\n      <th>Removed due to Nulls</th>\n      <th>count_x</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>Removed due to Variance</th>\n      <th>unique</th>\n      <th>count_y</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>entropy</th>\n      <th>Removed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.581139</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>B_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.4</td>\n      <td>0.547723</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>C_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>5</td>\n      <td>foo5</td>\n      <td>1</td>\n      <td>1.609438</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>D_x</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.581139</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>B_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.4</td>\n      <td>0.547723</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>C_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>5</td>\n      <td>foo5</td>\n      <td>1</td>\n      <td>1.609438</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>D_y</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "summary.merge(summary_cat, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   A_x      B_x     C_x             D_x      A_y      B_y     C_y             D_y\n",
       "npartitions=1                                                                                    \n",
       "0              float64  float64  object  datetime64[ns]  float64  float64  object  datetime64[ns]\n",
       "4                  ...      ...     ...             ...      ...      ...     ...             ...\n",
       "Dask Name: drop, 2 tasks"
      ],
      "text/html": "<div><strong>Dask DataFrame Structure:</strong></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A_x</th>\n      <th>B_x</th>\n      <th>C_x</th>\n      <th>D_x</th>\n      <th>A_y</th>\n      <th>B_y</th>\n      <th>C_y</th>\n      <th>D_y</th>\n    </tr>\n    <tr>\n      <th>npartitions=1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>float64</td>\n      <td>float64</td>\n      <td>object</td>\n      <td>datetime64[ns]</td>\n      <td>float64</td>\n      <td>float64</td>\n      <td>object</td>\n      <td>datetime64[ns]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div>Dask Name: drop, 2 tasks</div>"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}